{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9BQYP--mkSu"
   },
   "source": [
    "# Image Filtering\n",
    "\n",
    "Goal of the lecture:\n",
    "1. Understand and apply basic image filtering operations\n",
    "    - Average Filtering\n",
    "    - Median Filtering\n",
    "    - Sobel Filtering\n",
    "1. Learn how to define custom filters\n",
    "1. Utilize filter operations to denoise an image\n",
    "1. Download and open a satellite image from [Copernicus Dataspace](https://dataspace.copernicus.eu/) and apply filters on the satellite image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing libraries and defining _smart_ imshow function\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def custom_imshow(*args, **kwargs):\n",
    "    # force cmap to be gray\n",
    "    kwargs[\"cmap\"] = \"gray\"\n",
    "    # Force range to be 8-bit range\n",
    "    kwargs[\"vmin\"] = 0\n",
    "    kwargs[\"vmax\"] = 255\n",
    "    plt.figure(figsize = (2,2))\n",
    "    plt.imshow(*args, **kwargs)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Filtering\n",
    "\n",
    "Useful links:\n",
    "- Theoretical lecture\n",
    "- Videos of [Computerphile](https://www.youtube.com/user/Computerphile) on the topic\n",
    "    - [Mean Filtering](https://www.youtube.com/watch?v=C_zFhWdM4ic&ab_channel=Computerphile)\n",
    "    - [Sobel](https://www.youtube.com/watch?v=uihBwtPIBxM&ab_channel=Computerphile)\n",
    "    \n",
    "\n",
    "To avoid unhelpful issues with integer operations, the following section will use floats in the range (0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gray_imshow(*args, **kwargs):\n",
    "    \"\"\"Imshow wrapper which sets cmap=\"gray\" and disables the axis\"\"\"\n",
    "    kwargs[\"cmap\"] = \"gray\"\n",
    "    # no restrictions on vmin/vmax\n",
    "    # kwargs[\"vmin\"] = 0\n",
    "    # kwargs[\"vmax\"] = 255\n",
    "    plt.figure(figsize = (2,2))\n",
    "    plt.imshow(*args, **kwargs)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "def get_float_arr():\n",
    "    a = np.zeros((15, 15), dtype=np.float32)\n",
    "    a[:, 3:6] = 0.5\n",
    "    a[:, 6:9] = 1.0\n",
    "    a[:, 9:12] = 0.5\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = get_float_arr()\n",
    "# now we need to manually set vmin/vmax [0, 1]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gray_imshow(a, vmin=0, vmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_kernel = np.ones((3, 3))\n",
    "avg_out = ndimage.convolve(a, avg_kernel)\n",
    "print(avg_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does the following code produce the _wrong_ output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gray_imshow(avg_out, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gray_imshow(avg_out, vmin=0, vmax=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "norm_avg_out = avg_out / avg_kernel.sum()\n",
    "gray_imshow(norm_avg_out, vmin=0, vmax=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# watch out for implicit normalization of imshow for one channel inputs!\n",
    "gray_imshow(avg_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average filter:\n",
    "- Blurs edges\n",
    "    - Softer transitions (= smoothing effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In-course practice\n",
    "\n",
    "- Try out different kernel sizes and note the effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "avg_kernel = np.ones((15, 15))\n",
    "avg_out = ndimage.convolve(a, avg_kernel) / avg_kernel.sum()\n",
    "gray_imshow(avg_out, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "noisy_a = get_float_arr()\n",
    "\n",
    "for n_x, n_y in [(5, 5), (-5, -5), (2, 2), (-2, -2), (2, -2)]:\n",
    "    noisy_a[n_x, n_y] = 1.0\n",
    "gray_imshow(noisy_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_kernel = np.ones((3, 3))\n",
    "avg_out = ndimage.convolve(noisy_a, avg_kernel) / avg_kernel.sum()\n",
    "gray_imshow(avg_out, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Non-linear digital filtering technique\n",
    "- Reduces noise while preserves edges\n",
    "    - What other technique could be used to filter out noise without blurring the edges?\n",
    "- Effective for \"salt-and-pepper noise\"\n",
    "    - Sparsely occuring white and black pixels (defective pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inp = np.zeros((3, 3))\n",
    "inp[-1, -1] = inp[0, 0] = 1\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inp_flatten = inp.flatten()\n",
    "inp_flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inp_sorted = np.sort(inp_flatten)\n",
    "inp_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = (inp_sorted.size - 1) // 2\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inp_sorted[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gray_imshow(\n",
    "    ndimage.median_filter(noisy_a, size=(3, 3)),\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In-course practice\n",
    "\n",
    "Manually add noise with the maximum value to the input image that cannot be _filtered_ by the `3 x 3` median filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How can one achieve that?\n",
    "noisy_a = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "# We want to disurb the input in such a way that the median\n",
    "# is also \"noise\" -> We must disturb larger regions of the input image\n",
    "noisy_a = get_float_arr()\n",
    "\n",
    "for n_x, n_y in [(2, 2), (-5, -5)]:\n",
    "    noisy_a[n_x : n_x + 3, n_y : n_y + 3] = 1.0\n",
    "gray_imshow(noisy_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gray_imshow(\n",
    "    ndimage.median_filter(noisy_a, size=(3, 3)),\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    ")\n",
    "# Discuss features vs noise issue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# note that the contents sum to 0\n",
    "# Preserving center pixels with 2\n",
    "# Prewitt would only have ones\n",
    "sobel_x = np.array(\n",
    "    [\n",
    "        [-1, 0, 1],\n",
    "        [-2, 0, 2],\n",
    "        [-1, 0, 1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "gray_imshow(sobel_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = get_float_arr()\n",
    "sobel_x_a = ndimage.convolve(a, weights=sobel_x)\n",
    "print(sobel_x_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why are some values negative?\n",
    "    - What does that mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gray_imshow(a, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utilize implicit normalization\n",
    "# gray_imshow(np.absolute(sobel_x_a))\n",
    "gray_imshow(sobel_x_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "horz_a = get_float_arr().T\n",
    "gray_imshow(horz_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would the output of the sobel-x operation look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "horz_x_a = ndimage.convolve(horz_a, weights=sobel_x)\n",
    "print(horz_x_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In-course practice\n",
    "\n",
    "Define a Sobel-Y filter and apply it to `horz_a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sobel_y = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "sobel_y = np.array(\n",
    "    [\n",
    "        [1, 2, 1],\n",
    "        [0, 0, 0],\n",
    "        [-1, -2, -1],\n",
    "    ]\n",
    ")\n",
    "gray_imshow(sobel_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "horz_y_a = ndimage.convolve(horz_a, weights=sobel_y)\n",
    "gray_imshow(np.absolute(horz_y_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, try to construct a \"diagonal\" edge-detection filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "a = get_float_arr()\n",
    "sobel_xy = np.array(\n",
    "    [\n",
    "        [2, 1, 0],\n",
    "        [1, 0, -1],\n",
    "        [0, -1, -2],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Discuss visualization issue:\n",
    "xy_a = ndimage.convolve(a, weights=sobel_xy)\n",
    "# xy_a = ndimage.convolve(a.T, weights=sobel_xy)\n",
    "gray_imshow(np.absolute(xy_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "print(xy_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "diag_a = np.diag(np.ones(15))\n",
    "diag_a = np.flip(diag_a, 1)\n",
    "gray_imshow(diag_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "xy_a = ndimage.convolve(diag_a, weights=sobel_xy)\n",
    "gray_imshow(xy_a, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying on satellite images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recap: Searching for and downloading a satellite image\n",
    "\n",
    "These are codes you already know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "def get_access_token(username: str, password: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the access token for the Copernicus Data Store. This token is required to access the data for download.\n",
    "    The token is not required for querying the data. It is valid for 3600 seconds (1 hour).\n",
    "\n",
    "    ----------\n",
    "    username : str\n",
    "        The username for the Copernicus Data Store.\n",
    "    password : str\n",
    "        The password for the Copernicus Data Store.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"client_id\": \"cdse-public\",\n",
    "        \"username\": username,\n",
    "        \"password\": password,\n",
    "        \"grant_type\": \"password\",\n",
    "    }\n",
    "    try:\n",
    "        r = requests.post(\n",
    "            \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\",\n",
    "            data=data,\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "    except Exception as e:\n",
    "        raise Exception(\n",
    "            f\"Access token creation failed. Response from the server was: {r.json()}\"\n",
    "        )\n",
    "    return r.json()[\"access_token\"]\n",
    "    \n",
    "# you may enter the credentials directly in your notebook\n",
    "user_name = \"\"\n",
    "password = \"\"\n",
    "\n",
    "# the following code is for us to not have to share our secrets ;)\n",
    "user_p = Path(\"user.txt\")\n",
    "pwd_p = Path(\"secret.txt\")\n",
    "if user_p.exists():\n",
    "    user_name = user_p.read_text().strip()\n",
    "if pwd_p.exists():\n",
    "    password = pwd_p.read_text().strip()\n",
    "\n",
    "assert user_name != \"\", \"Please provide your user-name!\"\n",
    "assert password != \"\", \"Please provide your password!\"\n",
    "\n",
    "# return the access token\n",
    "access_token = get_access_token(user_name, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Optional, Iterable, Tuple\n",
    "from datetime import date\n",
    "from shapely.geometry import Point\n",
    "\n",
    "def dataspace_dataframe_from_attributes(\n",
    "    collection: str = \"SENTINEL-2\",\n",
    "    aoi: Optional[str] = None,\n",
    "    start_date: Optional[str] = None,\n",
    "    end_date: Optional[str] = None,\n",
    "    attributes: Optional[Iterable[Tuple[str, str, float]]] = None,\n",
    "    max_returned_items: int = 20\n",
    "):\n",
    "    \"\"\"\n",
    "    Get a dataframe of items from the Copernicus DataSpace API based on the given attributes.\n",
    "    The request is build based on the OData standard as documented at\n",
    "    https://documentation.dataspace.copernicus.eu/APIs/OData.html\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    collection : str\n",
    "        The collection to search for. Default is \"SENTINEL-2\".\n",
    "    aoi : str, optional\n",
    "        The area of interest in WKT format. Default is None.\n",
    "    start_date : str, optional\n",
    "        The start date in the format \"YYYY-MM-DD\". Default is None.\n",
    "    end_date : str, optional\n",
    "        The end date in the format \"YYYY-MM-DD\". Default is None.\n",
    "    attributes : Iterable[Tuple[str, str, float]], optional\n",
    "        The attributes to filter by. Default is None which means no filtering and is equivalent to an empty list.\n",
    "        Each tuple should be in the format (key, comparison, value).\n",
    "        The comparison should be one of \"lt\", \"le\", \"eq\", \"ge\", \"gt\".\n",
    "        Currently only attributes of type double and that are comparable are supported.\n",
    "    max_returned_items : int, optional\n",
    "        The maximum number of items to return. Default is 20. Must be in [0, 1000].\n",
    "    \"\"\"\n",
    "    if attributes is None:\n",
    "        attributes = []\n",
    "    request_str = \"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=\"\n",
    "    request_str += f\"Collection/Name eq '{collection}'\"\n",
    "    if aoi is not None:\n",
    "        request_str += f\" and OData.CSC.Intersects(area=geography'SRID=4326;{aoi}')\"\n",
    "    if start_date is not None:\n",
    "        request_str += f\" and ContentDate/Start gt {start_date}T00:00:00.000Z\"\n",
    "    if end_date is not None:\n",
    "        request_str += f\" and ContentDate/Start lt {end_date}T00:00:00.000Z\"\n",
    "    for k, comp, v in attributes:\n",
    "        assert comp in [\"lt\", \"le\", \"eq\", \"ge\", \"gt\"]\n",
    "        request_str += f\" and Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq '{k}' and att/OData.CSC.DoubleAttribute/Value {comp} {v:.2f})\"\n",
    "    # get all attributes\n",
    "    request_str += \"&$expand=Attributes\"\n",
    "    # get top n items\n",
    "    assert 0 <= max_returned_items <= 1000, f\"Copernicus API only allows returned items in [0, 1000], but {max_returned_items} is outside this range.\"\n",
    "    request_str += f\"&$top={max_returned_items}\"\n",
    "    json_result = requests.get(request_str).json()\n",
    "    json_vals = json_result['value']\n",
    "    return pd.DataFrame.from_dict(json_result['value'])\n",
    "\n",
    "start_date = date(year=2024, month=4, day=1)\n",
    "end_date = date(year=2024, month=4, day=30)\n",
    "satellite = \"SENTINEL-2\"\n",
    "latitude = 41.01963\n",
    "longitude = 28.99817\n",
    "\n",
    "poi = geopandas.GeoSeries([Point(longitude, latitude)], crs=\"EPSG:4326\").to_wkt()[0]\n",
    "\n",
    "products = dataspace_dataframe_from_attributes(\n",
    "    collection=satellite,\n",
    "    start_date=start_date.strftime(\"%Y-%m-%d\"),\n",
    "    end_date=end_date.strftime(\"%Y-%m-%d\"),\n",
    "    aoi=poi,\n",
    "    attributes=[('cloudCover', 'le', 1)]\n",
    ")\n",
    "products = products[products['Name'].str.contains(\"L2A\")]\n",
    "assert len(products) == 1, \"Expected only a single result\"\n",
    "assert products.iloc[0].Name == 'S2A_MSIL2A_20240413T084601_N0510_R107_T35TPF_20240413T145352.SAFE', \"Unexpected Name\"\n",
    "product_id = products.iloc[0].Id\n",
    "product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.rich import tqdm\n",
    "\n",
    "def download_file_with_progress(url: str, output_file: Path, update_session_headers: dict = None):\n",
    "    \"\"\"\n",
    "    Given a `url` as a String and an `output_file` as a file-path the item will\n",
    "    be downloaded and written to the `output_file`. If the `output_file` already\n",
    "    exists, it will be overwritten.\n",
    "    \"\"\"\n",
    "    s = requests.Session()\n",
    "    if update_session_headers is not None:\n",
    "        s.headers.update(update_session_headers)\n",
    "\n",
    "    # unfortunately, redirects don't follow the standard - we implement our own\n",
    "    response = s.head(url, allow_redirects=False)\n",
    "    while response.status_code in (301, 302, 303, 307):\n",
    "        url = response.headers['Location']\n",
    "        response = s.head(url, allow_redirects=False)\n",
    "        \n",
    "    chunk_size = 2**20  # MB\n",
    "    with s.get(url, stream=True) as resp:\n",
    "        with open(output_file, \"wb\") as f:\n",
    "            print(f\"Saving to {output_file}\")\n",
    "            for data in tqdm(\n",
    "                resp.iter_content(chunk_size=chunk_size), \n",
    "                total=int(resp.headers.get(\"content-length\", 0)) // chunk_size, \n",
    "                unit=\"MB\",\n",
    "                unit_scale=True,\n",
    "                desc=\"Downloading...\",\n",
    "            ):\n",
    "                f.write(data)\n",
    "                \n",
    "data_path = Path(\"./data\")\n",
    "data_path.mkdir(exist_ok=True)\n",
    "assert data_path.exists, \"Should exist after calling mkdir!\"\n",
    "\n",
    "tile_name = Path(products.iloc[0].Name)\n",
    "output_filepath = data_path / tile_name.with_suffix(\".SAFE.zip\")\n",
    "\n",
    "url = f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products({product_id})/$value\"\n",
    "download_file_with_progress(\n",
    "    url=url, \n",
    "    output_file=output_filepath, \n",
    "    update_session_headers={'Authorization': f'Bearer {access_token}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zipf = zipfile.ZipFile(output_filepath)\n",
    "zipf.extractall(path=\"data\")\n",
    "unzipped_dir = Path(data_path / tile_name.with_suffix(\".SAFE\"))\n",
    "assert unzipped_dir.exists(), f\"{unzipped_dir} does not exist!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering on satellite images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# discussion from last time\n",
    "def quant_norm_data(\n",
    "        data: np.ndarray, lower_quant: float = 0.01, upper_quant: float = 0.99\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize the data by quantiles `lower_quant/upper_quant`.\n",
    "    The quantiles are calculated globally/*across all channels*.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        The data to normalize.\n",
    "    lower_quant : float\n",
    "        The lower quantile. Default is 0.01.\n",
    "    upper_quant : float\n",
    "        The upper quantile. Default is 0.99.\n",
    "    \"\"\"\n",
    "    masked_data = np.ma.masked_equal(data, 0)\n",
    "    lq, uq = np.quantile(masked_data.compressed(), (lower_quant, upper_quant))\n",
    "    data = np.clip(data, a_min=lq, a_max=uq)\n",
    "    data = (data - lq) / (uq - lq)\n",
    "    return data\n",
    "\n",
    "\n",
    "def vis(data: np.ndarray, quant_norm: bool = False):\n",
    "    \"\"\"\n",
    "    Visualize an array by calling `imshow` with `cmap=\"gray\"` for 1 channel inputs and no cmap for 3 channel inputs.\n",
    "    Expected shape is either (H, W) or (H, W, 3) for 1 and 3 channel inputs respectively. Assumes RGB order for 3\n",
    "    channel inputs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.ndarray\n",
    "        The data to visualize. Expected shape is either (H, W) or (H, W, 3) for 1 and 3 channel inputs respectively.\n",
    "        Assumes RGB order for 3 channel inputs.\n",
    "    quant_norm : bool\n",
    "        Whether to quantile normalize the data. Default is False.\n",
    "    \"\"\"\n",
    "    if quant_norm:\n",
    "        data = quant_norm_data(data)\n",
    "    if data.ndim == 2:\n",
    "        plt.imshow(data, cmap=\"gray\")\n",
    "    elif data.ndim == 3:\n",
    "        plt.imshow(data)\n",
    "    else:\n",
    "        raise ValueError(f\"Expected data to have 2 or 3 dimensions, but got {data.ndim} dimensions.\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "class S2TileReader:\n",
    "    def __init__(self, directory: Path):\n",
    "        \"\"\"\n",
    "        Initialize the reader with a directory containing the SAFE file of a Sentinel-2 product.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory : Path\n",
    "            The directory containing the SAFE file of a Sentinel-2 product.\n",
    "        \"\"\"\n",
    "        assert directory.is_dir(), f\"{directory} is not a directory\"\n",
    "        self.image_files = list(directory.glob(f\"**/IMG_DATA/*.jp2\"))\n",
    "        if len(self.image_files) == 0:\n",
    "            self.image_files = list(directory.glob(f\"**/IMG_DATA/R60m/*.jp2\"))\n",
    "            self.image_files.extend(list(directory.glob(f\"**/IMG_DATA/R20m/*.jp2\")))\n",
    "            self.image_files.extend(list(directory.glob(f\"**/IMG_DATA/R10m/*.jp2\")))\n",
    "        self.band2file_mapping = self._bands()\n",
    "        self.bands = sorted(self.band2file_mapping.keys())\n",
    "        print(f\"{len(self.band2file_mapping)} images found in {directory}\")\n",
    "\n",
    "    def _bands(self):\n",
    "        \"\"\"\n",
    "        Extract the band names from the image files and create a mapping from band name to file path.\n",
    "\n",
    "        Example:\n",
    "        {\n",
    "            \"B01\": Path(\"path/to/B01.jp2\"),\n",
    "            \"B02\": Path(\"path/to/B02.jp2\"),\n",
    "            ...\n",
    "        }\n",
    "        or if the product has multiple resolutions:\n",
    "        {\n",
    "            \"B01_60m\": Path(\"path/to/R60m/B01.jp2\"),\n",
    "            \"B02_10m\": Path(\"path/to/R10m/B02.jp2\"),\n",
    "            ...\n",
    "        }\n",
    "        \"\"\"\n",
    "        return {\"_\".join(x.stem.split(\"_\")[2:]):x for x in self.image_files}\n",
    "\n",
    "    def read_band(self, band: str):\n",
    "        \"\"\"\n",
    "        Read the data of a specific band. The data is returned as a numpy array. If the band is a single channel,\n",
    "        the array will have shape (height, width). If the band is a multi-channel band, the array will have shape\n",
    "        (height, width, channels).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        band : str\n",
    "            The name of the band to read. Must be one of the bands in the product.\n",
    "            Use the `bands` attribute to see the available bands.\n",
    "        \"\"\"\n",
    "        assert band in self.bands, f\"Band {band} invalid. Please select one of {self.bands}\"\n",
    "        img_path = self.band2file_mapping[band]\n",
    "        with rasterio.open(self.band2file_mapping[band]) as f:\n",
    "            data = f.read()\n",
    "        if data.shape[0] == 1:\n",
    "            return data.squeeze(0)\n",
    "        elif data.shape[0] == 3:\n",
    "            return np.transpose(data, (1, 2, 0))\n",
    "\n",
    "\n",
    "s2_reader = S2TileReader(unzipped_dir)\n",
    "x = 500\n",
    "y = 800\n",
    "rgb_arr = np.stack(\n",
    "    [s2_reader.read_band(b) for b in (\"B04_60m\", \"B03_60m\", \"B02_60m\")],\n",
    "    axis=-1,\n",
    ")[x:x+700, y:y+700]\n",
    "vis(rgb_arr, quant_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 805   # for 60m bands\n",
    "y = 1035  # for 60m bands\n",
    "size = 200  # for 60m bands\n",
    "\n",
    "x, y, size = x*6, y*6, size*6\n",
    "rgb_arr = np.stack(\n",
    "    [s2_reader.read_band(b) for b in (\"B04_10m\", \"B03_10m\", \"B02_10m\")],\n",
    "    axis=-1,\n",
    ")[x:x+size, y:y+size]\n",
    "vis(rgb_arr, quant_norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_avg = ...\n",
    "kernel_sobel_x = ...\n",
    "kernel_sobel_y = ...\n",
    "kernel_sobel_xy = ...\n",
    "kernel_sobel_yx = ...\n",
    "kernel_laplace = ...\n",
    "\n",
    "kernels = {\n",
    "    \"Sobel X\": kernel_sobel_x,\n",
    "    \"Sobel Y\": kernel_sobel_y,\n",
    "    \"Sobel XY\": kernel_sobel_xy,\n",
    "    \"Sobel YX\": kernel_sobel_yx,\n",
    "    \"Median Blur\": kernel_avg,\n",
    "    \"Laplacian\": kernel_laplace,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "kernel_avg = np.array([\n",
    "    [1, 1, 1], \n",
    "    [1, 1, 1], \n",
    "    [1, 1, 1]\n",
    "]) / 9\n",
    "kernel_sobel_x = np.array([\n",
    "    [-1, 0, 1],\n",
    "    [-2, 0, 2],\n",
    "    [-1, 0, 1],\n",
    "])\n",
    "kernel_sobel_y = np.array([\n",
    "    [ 1,  2,  1], \n",
    "    [ 0,  0,  0], \n",
    "    [-1, -2, -1]\n",
    "])\n",
    "kernel_sobel_xy = np.array([\n",
    "        [2,  1,  0],\n",
    "        [1,  0, -1],\n",
    "        [0, -1, -2],\n",
    "])\n",
    "kernel_sobel_yx = np.array([\n",
    "        [ 0,  1, 2],\n",
    "        [-1,  0, 1],\n",
    "        [-2, -1, 0],\n",
    "])\n",
    "kernel_laplace = np.array([\n",
    "    [0,  1, 0], \n",
    "    [1, -4, 1], \n",
    "    [0,  1, 0]\n",
    "])\n",
    "\n",
    "kernels = {\n",
    "    \"Median Blur\": kernel_avg,\n",
    "    \"Laplacian\": kernel_laplace,\n",
    "    \"Sobel X\": kernel_sobel_x,\n",
    "    \"Sobel Y\": kernel_sobel_y,\n",
    "    \"Sobel XY\": kernel_sobel_xy,\n",
    "    \"Sobel YX\": kernel_sobel_yx,\n",
    "}\n",
    "gray_imshow(kernel_laplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "# display the binary classification and the edge detection\n",
    "plt.figure(figsize=(10, 20))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.imshow(quant_norm_data(rgb_arr))\n",
    "plt.title(\"Original\")\n",
    "\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.imshow(quant_norm_data(rgb2gray(rgb_arr)), cmap=\"gray\")\n",
    "plt.title(\"Grayscale\")\n",
    "\n",
    "for i, name in enumerate(kernels):\n",
    "    kernel = kernels[name]\n",
    "    plt.subplot(4, 2, i+3)\n",
    "    if name == \"Laplacian\":\n",
    "        gauss_kernel = np.array([\n",
    "            [1,  2, 1], \n",
    "            [2, 4, 2], \n",
    "            [1,  2, 1]\n",
    "        ]) / 16\n",
    "        res = convolve(rgb2gray(rgb_arr), gauss_kernel, mode=\"constant\", cval=0.0)\n",
    "        name += \" of Gaussian\"\n",
    "    res = convolve(rgb2gray(rgb_arr), kernel, mode=\"constant\", cval=0.0)\n",
    "    res = quant_norm_data(data=res, lower_quant=0.05, upper_quant=0.95)\n",
    "    plt.imshow(res, cmap='gray')\n",
    "    plt.title(f\"Convolution with {name}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMcIaFpMIiQL3Fx46uQpHLF",
   "name": "Lab4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "d950cc255805eca97bc9adaef38440cdd4d88c80fff2afb10853f0ffb81a073c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
